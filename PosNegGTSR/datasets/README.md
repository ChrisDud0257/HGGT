# Training and Testing dataset

## DF2K_OST Training Dataset

If you want to train with DF2K_OST datset,
- Firstly, please download them through the link [DIV2K(1-800 images for training)](https://data.vision.ee.ethz.ch/cvl/DIV2K/), [Flickr2K](https://cv.snu.ac.kr/research/EDSR/Flickr2K.tar) and [OST](https://github.com/xinntao/SFTGAN).
- Secondly, Merge all of the HR images into a file.
- Then, extract sub images, please modify ```'input_folder'``` to your DF2K_OST dataset directory. Modify ```'save_folder'``` to your save folder. And execute:
```bash
cd ImageEnhancement/scripts/data_preparation
python extract_subimages.py
```
- Before training, please modify the parameters ```datasets[train][dataroot_all_gt]``` in the ```.yml``` file. For example, for ```./PosNegGTSR/options/train/PosNegGTSR/train_LDL_DF2K_OST_Blind_x4.yml```,
you should modify the following parameters:
```bash
datasets:
  train:
    name: DF2K_OST
    type: OneStageDegradation_DF2K_Dataset
    dataroot_all_gt: /Path to/DF2K_OST subimages
```

## HGGT Training Dataset
We provide the training dataset, named HGGT, it has 20193 sets of training enhanced GTs together with their label information.

- Firstly, please download the training images from [GoogleDrive](https://drive.google.com/file/d/1RVc6zZ8XfcAxA11HCDwKLtScysdP6MK1/view?usp=share_link). The dataset structures are as follows:
```bash
Train/
    images/
        0-20193/
            original/
                imgA-x-y.png
                imgB-x1-y1.png
            01/
                imgA-x-y_01.png
                imgB-x1-y1_01.png
            02/
                imgA-x-y_02.png
                imgB-x1-y1_02.png
            03/
                imgA-x-y_03.png
                imgB-x1-y1_03.png
            04/
                imgA-x-y_04.png
                imgB-x1-y1_04.png
    labels/
        0-20193/
            A/
                imgA-x-y.json
                imgB-x1-y1.json
            B/
                imgA-x-y.json
                imgB-x1-y1.json
            C/
                imgA-x-y.json
                imgB-x1-y1.json
```
- For example, for each set of GTs, the original GT image ```imgA-x-y.png``` has its corresponding enhanced versions, ```imgA-x-y_01.png```, ```imgA-x-y_02.png```, ```imgA-x-y_03.png```, ```imgA-x-y_04.png```, the five images are placed in the folder ```original/```, ```01/```, ```02/```, ```03/```, ```04/``` respectively.

- As for the label, in the ```labels/0-20193/``` folder, the three different folder ```A/```, ```B/```, ```C/``` means each set of images is annotated by three differnt people, we denote ```A, B, C``` for representing the three people. For example, the image set ```imgA-x-y.png, imgA-x-y_01.png, imgA-x-y_02.png, imgA-x-y_03.png, imgA-x-y_04.png``` are annotated by person 'A', and the annotation information is saved in the file ```labels/0-20193/A/imgA-x-y.json```. The ```imgA-x-y.json``` has the same name with the original GT image ```imgA-x-y.png```, and it records the total four enhanced GTs' annotation results.

- Before training, as for the training set, please download and unzip to a folder. then please modify the ```datasets[train][dataroot_all_gt]``` and ```datasets[train][dataroot_all_json]``` parameters in the ```.yml``` file. For example, to train with our postive GT, in the ```.yml``` file
```./PosNegGTSR/options/train/PosNegGTSR/train_RRDBGAN_PosNegGT_Blind_Pos_x4.yml```, you should modify the following parameters:
```bash
datasets:
  train:
    name: PosNegGT0-20193
    type: PosNegGTPosDataset
    dataroot_all_gt: /Path to/Train/images/0-20193
    dataroot_all_json: /Path to/Train/labels/0-20193
```

## Validation dataset
We provide the widely-used Set5 dataset with their GT images and low-quality(LQ) images in the folder ```./PosNegGT/datasets/Test/```, the LQ images are generated by imposing the same blind degradation factors as our training stage.
- Note that, the validation dataset has huge difference with our testing dataset, since the validation dataset doesn't have any enhanced GT images. The main purpose for the validation dataset is to provide some LQ images for you, thus your model could generate validation SR results during your training stage, then you should observe them and make sure that your model could generate SR results with good perception quality.
- Thus, the final validation results will not represent the quantitative metrics results with our testing dataset. It just gives you some subjective results, and you could use them to judge whether your model has huge divergence with your main purpose.
- Please modify the parameters ```datasets[val]``` in the ```.yml``` file. For example, in ```./PosNegGTSR/options/train/PosNegGTSR/train_RRDBGAN_PosNegGT_Blind_Pos_x4.yml```, you should modify the following parameters:
```bash
datasets:
  val:
    name: Set5
    type: PairedImageDataset
    dataroot_gt: datasets/Test/GT/Set5 #path to your own testing dataset, we also provide our validation GT dataset in "datasets/Test/GT/Set5"
    dataroot_lq: datasets/Test/Blind_Degradation_Benchmark_LQ/Set5 #path to your own testing dataset, we also provide our validation LQ dataset in "datasets/Test/Blind_Degradation_Benchmark_LQ/Set5"
    io_backend:
      type: disk
```

## Testing dataset
To evaluate the performance of Real-ISR models trained on our dataset quantitatively, we construct a test set using the same steps as in the construction of our training set. In specific, 100 patch groups with at least 2 ‘Positive’ GTs are constructed. The input LR patches are generated by using the same degradation process as in the training process. The LR patches together with their GTs are used to quantitatively evaluate the Real-ISR models. We denote this dataset as Test-100.

- Firstly, please download Test-100 through [GoogleDrive](https://drive.google.com/file/d/1Cic8bfE7e3gBDabsfKmge5R0BRrfdazv/view?usp=sharing). The dataset structure is as follows:

```bash
Test/
    GT/
        Test-100/
            images/
                original/
                    imgC-x-y.png
                    imgD-x1-y1.png
                01/
                    imgC-x-y_01.png
                    imgD-x1-y1_01.png
                02/
                    imgC-x-y_02.png
                    imgD-x1-y1_02.png
                03/
                    imgC-x-y_03.png
                    imgD-x1-y1_03.png
                04/
                    imgC-x-y_04.png
                    imgD-x1-y1_04.png
            labels/
                A/
                   imgC-x-y.json
                   imgD-x1-y1.json
                B/
                   imgC-x-y.json
                   imgD-x1-y1.json
                C/
                   imgC-x-y.json
                   imgD-x1-y1.json`
    Blind_Degradation_Benchmark_LQ/
        Test-100/
            Blind_LR/
                imgC-x-y.png
                imgD-x-y.png

```

- The GT images are saved in ```GT/Test-100/images/```, while the annotation labels are saved in ```GT/Test-100/labels/```,
the low-quality images are saved in ```Blind_Degradation_Benchmark_LQ/Test-100/Blind_LR/```, it has the same image name as the original GT.
- Before testing, please download them and we recommend you to put them into ```./datasets/``` folder.
- Please modify the parameters ```datasets``` in the ```.yml``` file. For example,
 in ```./PosNegGTSR/options/test/PosNegGTSR/test_RRDBGAN_PosNegGT_Blind_Pos_x4.yml```, please modify:

```bash
datasets:
  test_1:
    name: Test-100
    type: PairedImageDataset
    dataroot_gt: datasets/Test/GT/Test-100/images/Original #/Path to/Test-100/images/original
    dataroot_lq: datasets/Test/Blind_Degradation_Benchmark_LQ/Test-100/Blind_LR #/Path to/Test-100/Blind_LR
    io_backend:
      type: disk
```

## For evaluation with metrics
Please modify the parameters ```--gts [path to the 'GT/Test-100/images' path]```(make sure in this path, it has 'original/, 01/,02/,03/,04/' folders), ```--restored [path to your SR result path]```, ```--json_path [path to the 'GT/Test-100/labels/' path]```(make sure in this path, it has 'A/, B/, C/' folders). 
- For example, for ```./PosNegGTSR/scripts/metrics/calculate_multigt_labeled_psnr_ssim.py```, please modify as follows:
```bash
    parser.add_argument('--gts', type=str, default='../../datasets/Test/GT/Test-100/images', help='Path to gt (Ground-Truth)')
    parser.add_argument('--restored', type=str, default='../../results/BSRGAN_DF2K_OST_Blind_x4/visulization/Test-100', help='Path to restored images')
    parser.add_argument('--json_path', type=str, default='../../datasets/Test/GT/Test-100/labels')
```




